{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text = \"\"\"LangChain is a framework for developing applications powered by language models. It can be used for chatbots, Generative Question-Answering (GQA), summarization, and much more.\n",
    "\"\"\"\n",
    "\n",
    "loader = TextLoader(text)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.transformers import LLMGraphTransformer\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d555140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graph_stores import Neo4jGraphStore\n",
    "\n",
    "\n",
    "graph_store = Neo4jGraphStore(url=\"neo4l://localhost:7687\", username=\"neo4j\", password=\"test\")\n",
    "graph_store.write_graph(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03506dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llam_index.core.response_synthesis import ResponseSynthesizer\n",
    "\n",
    "graph_rag_retriever =KnowledgeGraphRAGRetriever(storage_context=graph_store.storage_context, verbose=True)\n",
    "query_engine = RetrieverQueryEngine.from_args(graph_rag_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and_synthesize(query):\n",
    "    retrieved_context = query_engine.query(query)\n",
    "    response = response_synthesizer.synthesize(query, retrieved_context)\n",
    "    print(f\"Query:{query}\")\n",
    "    print(f\"Answer: {response}\")\n",
    "\n",
    "response_synthesizer = ResponseSynthesizer(llm)\n",
    "\n",
    "query_and_synthesize(\"Where does Sarah work?\")\n",
    "\n",
    "query_and_synthesize(\"Who works for prismaticAI?\")\n",
    "\n",
    "query_and_synthesize(\"Does Michael wprk for the same company as Sarah?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8457d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
